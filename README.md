ğŸ“¨ Reply Classification Project

This project classifies email replies into positive, negative, or neutral categories. It includes both a baseline ML model and a fine-tuned transformer model, and provides a FastAPI service for real-time predictions.

ğŸ“‚ Project Structure
Reply-Classification/
â”‚
â”œâ”€ env/                    # Python virtual environment (optional to include in repo)
â”œâ”€ data/                   # CSV dataset of email replies
â”œâ”€ models/                 # Saved model files (Logistic Regression & DistilBERT)
â”œâ”€ notebooks/              # Jupyter notebooks for experimentation
â”œâ”€ main.py                 # FastAPI application
â”œâ”€ requirements.txt        # Python dependencies
â”œâ”€ Dockerfile              # Optional: for containerization
â”œâ”€ README.md               # Project documentation
â””â”€ answers.md              # Short answer reasoning for Part C

âš™ï¸ Setup Instructions
1. Python Environment

Install Python 3.11.9.

Create a virtual environment:

python -m venv env


Activate the environment:

Windows (PowerShell):

.\env\Scripts\Activate.ps1


macOS/Linux:

source env/bin/activate


Install required libraries:

pip install -r requirements.txt

2. Install Dependencies

Libraries used in the project:

pandas, numpy â€“ Data processing

scikit-learn â€“ Logistic Regression & metrics

torch, transformers â€“ Fine-tuning DistilBERT

fastapi, uvicorn â€“ API deployment

python-multipart â€“ For FastAPI JSON parsing (if needed)

ğŸ§© ML/NLP Pipeline
Steps:

Load and preprocess the CSV dataset:

Clean text

Handle missing values

Train baseline model:

Logistic Regression

LightGBM (optional)

Fine-tune transformer:

distilbert-base-uncased using Hugging Face

Evaluate models:

Accuracy

F1-score

Comparison:

Logistic Regression: stable, faster, good for small datasets

DistilBERT: higher accuracy but sometimes hallucinate, slower inference

âœ… Production choice: Logistic Regression model for reliability.

ğŸš€ FastAPI Deployment
Run the API
uvicorn main:app --reload


Open in browser: http://127.0.0.1:8000/docs

Example input:

{
  "text": "Looking forward to the demo!"
}


Example output:

{
  "label": "positive",
  "confidence": 0.87
}

ğŸ“– Use Case Guide

Open reply_classification_report.html to view model evaluation metrics.

Start the Uvicorn server.

Navigate to /docs to test API predictions.
